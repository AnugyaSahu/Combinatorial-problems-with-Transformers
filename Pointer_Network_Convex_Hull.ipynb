{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8AVEc9Su8Km"
   },
   "source": [
    "# Pointer Network - Convex Hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMntU4jUu_v1"
   },
   "source": [
    "This Jupyter Notebook outlines a solution to the planar convex hull problem by employing the pointer network architecture. We first generate a toy dataset consisting of 2D uniformly distributed points and convex hull indices by using `numpy`, `scipy`, and `shapely`. We then define a neural network architecture that generates input and target embeddings using a transformer encoder and decoder, respectively, followed by a pointer network to express a conditional probability over the input tokens. Lastly, we train the model and visualize a sample output.\n",
    "\n",
    "For a high-level overview of this topic, refer to the Medium article [Pointer Networks with Transformers](https://medium.com/@masonmcgough/pointer-networks-with-transformers-1a01d83f7543)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNjqIHEhXmAp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pprint import pprint\n",
    "from typing import Tuple, Union, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely import geometry\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_coordinates_from_file(file_path):\n",
    "    coordinates = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    x = float(parts[0])\n",
    "                    y = float(parts[1])\n",
    "                except(ValueError):\n",
    "                    continue\n",
    "                coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "file_path_test_50 = r\"tsp_unif_test50_100_100000.txt\"\n",
    "file_path_train_50 = r\"tsp_unif50_10000_100000_1000.txt\"\n",
    "file_path_test_100 = r\"tsp_unif_test100_100_100000.txt\"\n",
    "file_path_train_100 = r\"tsp_unif100_10000_100000_1000.txt\"\n",
    "\n",
    "coordinates_test50 = read_coordinates_from_file(file_path_test_50)\n",
    "test50 = np.array(coordinates_test50)\n",
    "coordinates_train50 = read_coordinates_from_file(file_path_train_50)\n",
    "train50 = np.array(coordinates_train50)\n",
    "\n",
    "coordinates_test100 = read_coordinates_from_file(file_path_test_100)\n",
    "test100 = np.array(coordinates_test100)\n",
    "\n",
    "coordinates_train100 = read_coordinates_from_file(file_path_train_100)\n",
    "train100 = np.array(coordinates_train100)\n",
    "\n",
    "print(test50.shape, train50.shape, test100.shape, train100.shape)\n",
    "\n",
    "testinstances50 = []\n",
    "for i in range(0, 5000, 50):\n",
    "    testinstances50.append(test50[i:i+50, :])\n",
    "testinstances50 = np.array(testinstances50)\n",
    "print(testinstances50.shape)\n",
    "optimal_distances_test50 = []\n",
    "for i in range(testinstances50.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(testinstances50.shape[1]-1):\n",
    "        distance += np.linalg.norm(testinstances50[i][j] -  testinstances50[i][j+1])\n",
    "    optimal_distances_test50.append(distance)\n",
    "optimal_distances_test50 = np.array(optimal_distances_test50)\n",
    "\n",
    "traininstances50 = []\n",
    "for i in range(0, 1500000, 50):\n",
    "    traininstances50.append(train50[i:i+50, :])\n",
    "traininstances50 = np.array(traininstances50)\n",
    "optimal_distances_train50 = []\n",
    "for i in range(traininstances50.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(traininstances50.shape[1]-1):\n",
    "        distance += np.linalg.norm(traininstances50[i][j] -  traininstances50[i][j+1])\n",
    "    optimal_distances_train50.append(distance)\n",
    "optimal_distances_train50 = np.array(optimal_distances_train50)\n",
    "testinstances100 = []\n",
    "for i in range(0, 10000, 100):\n",
    "    testinstances100.append(test100[i:i+100, :])\n",
    "testinstances100 = np.array(testinstances100)\n",
    "optimal_distances_test100 = []\n",
    "for i in range(testinstances100.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(testinstances100.shape[1]-1):\n",
    "        distance += np.linalg.norm(testinstances100[i][j] -  testinstances100[i][j+1])\n",
    "    optimal_distances_test100.append(distance)\n",
    "optimal_distances_test100 = np.array(optimal_distances_test100)\n",
    "\n",
    "traininstances100 = []\n",
    "for i in range(0, 1000000, 100):\n",
    "    traininstances100.append(train100[i:i+100, :])\n",
    "traininstances100 = np.array(traininstances100)\n",
    "optimal_distances_train100 = []\n",
    "for i in range(traininstances100.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(traininstances100.shape[1]-1):\n",
    "        distance += np.linalg.norm(traininstances100[i][j] -  traininstances100[i][j+1])\n",
    "    optimal_distances_train100.append(distance)\n",
    "optimal_distances_train100 = np.array(optimal_distances_train100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(testinstances50.shape), print(traininstances50.shape), print(testinstances100.shape), print(traininstances100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TOKENS = {\n",
    "#   '<sos>': 0,\n",
    "#   '<eos>': 1\n",
    "# }\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "temp1 = np.array(([0.0, 0.0])).reshape(1,2)\n",
    "TOKENS = {\n",
    "  '<eos>': 0\n",
    "}\n",
    "class TSPDataset50():\n",
    "    def __init__(self):\n",
    "        self.points = []\n",
    "        self.points_original = []\n",
    "        self.targets = []\n",
    "        for i in traininstances50:\n",
    "            num_rows = i.shape[0]\n",
    "            row_indices = np.arange(num_rows)\n",
    "            np.random.shuffle(row_indices)\n",
    "            shuffled_array = i[row_indices]\n",
    "            inverse_indices = np.argsort(row_indices)\n",
    "            self.points_original.append(shuffled_array)\n",
    "            #standardisation\n",
    "            self.points.append(scaler.fit_transform(shuffled_array))\n",
    "            self.targets.append(inverse_indices)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        points, targets = torch.tensor(self.points[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.int64)\n",
    "        length = torch.tensor(len(points), dtype=torch.int64)\n",
    "        points_original = torch.tensor(self.points_original[idx], dtype=torch.float32)\n",
    "        return points, targets, length, points_original\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.points)\n",
    "    \n",
    "class TSPDatasetTest50():\n",
    "    def __init__(self):\n",
    "        self.max_samples = len(testinstances50)\n",
    "        self.points = []\n",
    "        self.points_original = []\n",
    "        self.targets = []\n",
    "        for i in testinstances50:\n",
    "            num_rows = i.shape[0]\n",
    "            row_indices = np.arange(num_rows)\n",
    "            np.random.shuffle(row_indices)\n",
    "            shuffled_array = i[row_indices]\n",
    "            inverse_indices = np.argsort(row_indices)\n",
    "            self.points_original.append(shuffled_array)\n",
    "            #standardisation\n",
    "            self.points.append(scaler.fit_transform(shuffled_array))\n",
    "            self.targets.append(inverse_indices)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        points, targets = torch.tensor(self.points[idx],dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.int64)\n",
    "        length = torch.tensor(len(points), dtype=torch.int64)\n",
    "        points_original = torch.tensor(self.points_original[idx], dtype=torch.float32)\n",
    "        return points, targets, length, points_original\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.points)\n",
    "    \n",
    "class TSPDataset100():\n",
    "    def __init__(self):\n",
    "        self.max_samples = len(traininstances100)\n",
    "        self.points = []\n",
    "        self.points_original = []\n",
    "        self.targets = []\n",
    "        for i in traininstances100:\n",
    "            num_rows = i.shape[0]\n",
    "            row_indices = np.arange(num_rows)\n",
    "            np.random.shuffle(row_indices)\n",
    "            shuffled_array = i[row_indices]\n",
    "            inverse_indices = np.argsort(row_indices)\n",
    "            self.points_original.append(shuffled_array)\n",
    "            #standardisation\n",
    "            self.points.append(scaler.fit_transform(shuffled_array))\n",
    "            self.targets.append(inverse_indices)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        points, targets = torch.tensor(self.points[idx],dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.int64)\n",
    "        length = torch.tensor(len(points), dtype=torch.int64)\n",
    "        points_original = torch.tensor(self.points_original[idx], dtype=torch.float32)\n",
    "        return points, targets, length, points_original\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.points)\n",
    "\n",
    "class TSPDatasetTest100():\n",
    "    def __init__(self):\n",
    "        self.max_samples = len(testinstances100)\n",
    "        self.points = []\n",
    "        self.points_original = []\n",
    "        self.targets = []\n",
    "        for i in testinstances100:\n",
    "            num_rows = i.shape[0]\n",
    "            row_indices = np.arange(num_rows)\n",
    "            np.random.shuffle(row_indices)\n",
    "            shuffled_array = i[row_indices]\n",
    "            inverse_indices = np.argsort(row_indices)\n",
    "            self.points_original.append(shuffled_array)\n",
    "            #standardisation\n",
    "            self.points.append(scaler.fit_transform(shuffled_array))\n",
    "            self.targets.append(inverse_indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        points, targets = torch.tensor(self.points[idx],dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.int64)\n",
    "        length = torch.tensor(len(points), dtype=torch.int64)\n",
    "        points_original = torch.tensor(self.points_original[idx], dtype=torch.float32)\n",
    "        return points, targets, length, points_original\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLwERhUU1Ql3"
   },
   "source": [
    "# Pointer Network Architecture\n",
    "\n",
    "Here we define a series of functions that we will need to construct our architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcFB0Bcy3AGW"
   },
   "source": [
    "\n",
    "\n",
    "This is where we define the pointer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42cpCUo0YlAy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info_value_of_dtype(dtype: torch.dtype):\n",
    "  \"\"\"\n",
    "  Returns the `finfo` or `iinfo` object of a given PyTorch data type. Does not allow torch.bool.\n",
    "\n",
    "  Adapted from allennlp by allenai:\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n",
    "  \"\"\"\n",
    "\n",
    "  if dtype == torch.bool:\n",
    "    raise TypeError(\"Does not support torch.bool\")\n",
    "  elif dtype.is_floating_point:\n",
    "    return torch.finfo(dtype)\n",
    "  else:\n",
    "    return torch.iinfo(dtype)\n",
    "\n",
    "\n",
    "def min_value_of_dtype(dtype: torch.dtype):\n",
    "  \"\"\"\n",
    "  Returns the minimum value of a given PyTorch data type. Does not allow torch.bool.\n",
    "\n",
    "  Adapted from allennlp by allenai:\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n",
    "  \"\"\"\n",
    "\n",
    "  return info_value_of_dtype(dtype).min\n",
    "\n",
    "def masked_log_softmax(\n",
    "  x: torch.Tensor,\n",
    "  mask: torch.Tensor,\n",
    "  dim: int = -1,\n",
    "  eps: float = 1e-45\n",
    ") -> torch.Tensor:\n",
    "  \"\"\"\n",
    "  Apply softmax to x with masking.\n",
    "\n",
    "  Adapted from allennlp by allenai:\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n",
    "\n",
    "  Args:\n",
    "    x - Tensor of arbitrary shape to apply softmax over.\n",
    "    mask - Binary mask of same shape as x where \"False\" indicates elements\n",
    "      to disregard from operation.\n",
    "    dim - Dimension over which to apply operation.\n",
    "    eps - Stability constant for log operation. Added to mask to avoid NaN\n",
    "      values in log.\n",
    "  Outputs:\n",
    "    Tensor with same dimensions as x.\n",
    "  \"\"\"\n",
    "\n",
    "  x = x + (mask.float() + eps).log()\n",
    "  return torch.nn.functional.log_softmax(x, dim=dim)\n",
    "\n",
    "def masked_max(\n",
    "  x: torch.Tensor,\n",
    "\tmask: torch.Tensor,\n",
    "\tdim: int,\n",
    "\tkeepdim: bool = False\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "  \"\"\"\n",
    "  Apply max to x with masking.\n",
    "\n",
    "  Adapted from allennlp by allenai:\n",
    "    https://github.com/allenai/allennlp/blob/master/allennlp/nn/util.py\n",
    "\n",
    "  Args:\n",
    "    x - Tensor of arbitrary shape to apply max over.\n",
    "    mask - Binary mask of same shape as x where \"False\" indicates elements\n",
    "      to disregard from operation.\n",
    "    dim - Dimension over which to apply operation.\n",
    "    keepdim - If True, keeps dimension dim after operation.\n",
    "  Outputs:\n",
    "    A ``torch.Tensor`` of including the maximum values.\n",
    "  \"\"\"\n",
    "\n",
    "  x_replaced = x.masked_fill(~mask, min_value_of_dtype(x.dtype))\n",
    "  max_value, max_index = x_replaced.max(dim=dim, keepdim=keepdim)\n",
    "  return max_value, max_index\n",
    "\n",
    "def convert_binary_mask_to_infinity_mask(mask: torch.Tensor) -> torch.Tensor:\n",
    "  \"\"\"\n",
    "  Convert the 0 and 1 elements in a binary mask to -inf and 0 for the\n",
    "    transformer.\n",
    "\n",
    "  Args:\n",
    "    mask: Binary mask tensor.\n",
    "  Outputs:\n",
    "    Infinity mask tensor with same size as mask.\n",
    "  \"\"\"\n",
    "\n",
    "  return mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC2Hwa712_2x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointerNetwork(nn.Module):\n",
    "  \"\"\"\n",
    "  From \"Pointer Networks\" by Vinyals et al. (2017)\n",
    "\n",
    "  Adapted from pointer-networks-pytorch by ast0414:\n",
    "    https://github.com/ast0414/pointer-networks-pytorch\n",
    "\n",
    "  Args:\n",
    "    n_hidden: The number of features to expect in the inputs.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    n_hidden: int\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.n_hidden = n_hidden\n",
    "    self.w1 = nn.Linear(n_hidden, n_hidden, bias=False)\n",
    "    self.w2 = nn.Linear(n_hidden, n_hidden, bias=False)\n",
    "    self.v = nn.Linear(n_hidden, 1, bias=False)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    x_decoder: torch.Tensor,\n",
    "    x_encoder: torch.Tensor,\n",
    "    mask: torch.Tensor,\n",
    "    eps: float = 1e-16\n",
    "  ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x_decoder: Encoding over the output tokens.\n",
    "      x_encoder: Encoding over the input tokens.\n",
    "      mask: Binary mask over the softmax input.\n",
    "    Shape:\n",
    "      x_decoder: (B, Ne, C)\n",
    "      x_encoder: (B, Nd, C)\n",
    "      mask: (B, Nd, Ne)\n",
    "    \"\"\"\n",
    "\n",
    "    # (B, Nd, Ne, C) <- (B, Ne, C)\n",
    "    encoder_transform = self.w1(x_encoder).unsqueeze(1).expand(\n",
    "      -1, x_decoder.shape[1], -1, -1)\n",
    "    # (B, Nd, 1, C) <- (B, Nd, C)\n",
    "    decoder_transform = self.w2(x_decoder).unsqueeze(2)\n",
    "    # (B, Nd, Ne) <- (B, Nd, Ne, C), (B, Nd, 1, C)\n",
    "    prod = self.v(torch.tanh(encoder_transform + decoder_transform)).squeeze(-1)\n",
    "    # (B, Nd, Ne) <- (B, Nd, Ne)\n",
    "    log_score = masked_log_softmax(prod, mask, dim=-1, eps=eps)\n",
    "    return log_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional Encoding Layer.\n",
    "    Based on: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    Explaination: https://medium.com/@a.arun283/a-deeper-look-into-the-positional-encoding-method-in-transformer-architectures-7e98f32a925f\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        \"\"\"\n",
    "        Initialize Positional Encoding Layer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Hidden dimension of the model\n",
    "            dropout (float, optional): Optional dropout of layer. Defaults to 0.1.\n",
    "            max_len (int, optional): Max. length of the PE. Defaults to 5000.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the Positional Encoding Layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input (seq_len, batch_size, embedding_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output (seq_len, batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        x = x.to(device) + self.pe[:x.size(0)].to(device)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axR9vU0k2loy"
   },
   "source": [
    "We now put all of those pieces together to create `ConvexNet`, our PyTorch module for modeling our planar convex hull data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZziQxP4UgUiY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvexNet(nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    c_inputs: int = 5,\n",
    "    c_embed: int = 8,\n",
    "    n_heads: int = 2,\n",
    "    n_layers: int = 1,\n",
    "    dropout: float = 0.1,\n",
    "    c_hidden: int = 2\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.c_hidden = c_hidden\n",
    "    self.c_inputs = c_inputs\n",
    "    self.c_embed = c_embed\n",
    "    self.n_heads = n_heads\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout = dropout\n",
    "\n",
    "    self.embedding = nn.Linear(c_inputs, c_embed, bias=False)\n",
    "    encoder_layers = nn.TransformerEncoderLayer(c_embed, n_heads, c_hidden, dropout)\n",
    "    self.encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "    decoder_layers = nn.TransformerDecoderLayer(c_embed, n_heads, c_hidden, dropout)\n",
    "    self.decoder = nn.TransformerDecoder(decoder_layers, n_layers)\n",
    "    self.pointer = PointerNetwork(n_hidden=c_embed)\n",
    "    self.pos_encoder = PositionalEncoding(self.c_hidden)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    batch_data: torch.Tensor,\n",
    "    batch_lengths: torch.Tensor,\n",
    "    training = True,\n",
    "    batch_labels: Optional[torch.Tensor] = None\n",
    "  ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # assumes batch-first inputs\n",
    "    batch_size = batch_data.shape[0]\n",
    "    max_seq_len = batch_data.shape[1]\n",
    "    c_embed = self.c_embed\n",
    "    n_heads = self.n_heads\n",
    "\n",
    "    x_embed = self.embedding(batch_data)\n",
    "    encoder_outputs = self.encoder(x_embed.permute(1, 0, 2))\n",
    "\n",
    "    # make mask\n",
    "    range_tensor = torch.arange(max_seq_len, device=batch_lengths.device,\n",
    "      dtype=batch_lengths.dtype).expand(batch_size, max_seq_len - len(TOKENS), max_seq_len)\n",
    "    each_len_tensor = batch_lengths.view(-1, 1, 1).expand(-1, max_seq_len - len(TOKENS), max_seq_len)\n",
    "    mask_tensor = (range_tensor < each_len_tensor)\n",
    "    mask_tensor[:, :, 0] = False\n",
    "\n",
    "    if training:\n",
    "      # teacher forcing\n",
    "      # pass through decoder\n",
    "      # here memory_mask is (batch_size * n_heads, len_decoder_seq, len_encoder_seq)\n",
    "      # https://discuss.pytorch.org/t/memory-mask-in-nn-transformer/55230/5\n",
    "      _bl = batch_labels[:, :-1].permute(1, 0).unsqueeze(-1)\n",
    "      _bl = _bl.expand(-1, batch_size, c_embed)\n",
    "      decoder_input = torch.gather(encoder_outputs, dim=0, index=_bl)\n",
    "      decoder_mask = mask_tensor.repeat((n_heads, 1, 1))\n",
    "      dm = convert_binary_mask_to_infinity_mask(decoder_mask)\n",
    "      tgt_mask = nn.Transformer.generate_square_subsequent_mask(len(decoder_input)).to(dm.device)\n",
    "      #positional encoding\n",
    "      decoder_input = self.pos_encoder.forward(decoder_input.to(\"cuda\"))\n",
    "      decoder_outputs = self.decoder(decoder_input, encoder_outputs,\n",
    "        tgt_mask=tgt_mask, memory_mask=dm)\n",
    "\n",
    "      # pass through pointer network\n",
    "      log_pointer_scores = self.pointer(\n",
    "        decoder_outputs.permute(1, 0, 2),\n",
    "        encoder_outputs.permute(1, 0, 2),\n",
    "        mask_tensor)\n",
    "      _, masked_argmaxs = masked_max(log_pointer_scores, mask_tensor, dim=-1)\n",
    "      return log_pointer_scores, masked_argmaxs\n",
    "    else:\n",
    "      #\n",
    "      log_pointer_scores = []\n",
    "      masked_argmaxs = []\n",
    "      _bl = batch_labels[:, :1].permute(1, 0).unsqueeze(-1)\n",
    "      _bl = _bl.expand(-1, batch_size, c_embed)\n",
    "      decoder_input = torch.gather(encoder_outputs, dim=0, index=_bl)\n",
    "      for _ in range(max_seq_len - len(TOKENS)):\n",
    "        # pass through decoder network\n",
    "        decoder_mask = mask_tensor[:, :len(decoder_input)].repeat((n_heads, 1, 1))\n",
    "        dm = convert_binary_mask_to_infinity_mask(decoder_mask)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(len(decoder_input)).to(dm.device)\n",
    "        ##positional encoding\n",
    "        decoder_input = self.pos_encoder.forward(decoder_input.to(\"cuda\"))\n",
    "        decoder_outputs = self.decoder(decoder_input, encoder_outputs,\n",
    "          tgt_mask=tgt_mask, memory_mask=dm)\n",
    "        \n",
    "        # pass through pointer network\n",
    "        mask_subset = mask_tensor[:, :len(decoder_outputs)]\n",
    "        log_pointer_score = self.pointer(\n",
    "          decoder_outputs.permute(1, 0, 2),\n",
    "          encoder_outputs.permute(1, 0, 2),\n",
    "          mask_subset)\n",
    "        _, masked_argmax = masked_max(log_pointer_score, mask_subset, dim=-1)\n",
    "    \n",
    "        # append new predictions\n",
    "        log_pointer_scores.append(log_pointer_score[:, -1, :])\n",
    "        new_maxes = masked_argmax[:, -1]\n",
    "        masked_argmaxs.append(new_maxes)\n",
    "        #print(new_maxes)\n",
    "        \n",
    "        # mask out predicted inputs\n",
    "        new_max_mask = torch.zeros((mask_tensor.shape[0], mask_tensor.shape[2]),\n",
    "          dtype=torch.bool, device=mask_tensor.device)\n",
    "        new_max_mask = new_max_mask.scatter(1, new_maxes.unsqueeze(1), True)\n",
    "        #new_max_mask[:, :2] = False\n",
    "        new_max_mask = new_max_mask.unsqueeze(1).expand(-1, mask_tensor.shape[1], -1)\n",
    "        #print(mask_tensor, new_max_mask)\n",
    "        mask_tensor[new_max_mask] = False\n",
    "\n",
    "        # prepare inputs for next iteration\n",
    "        next_indices = torch.stack(masked_argmaxs, dim=0).unsqueeze(-1).expand(-1, batch_size, c_embed)\n",
    "        decoder_input = torch.cat((encoder_outputs[:1],\n",
    "          torch.gather(encoder_outputs, dim=0, index=next_indices)), dim=0)\n",
    "      \n",
    "      log_pointer_scores = torch.stack(log_pointer_scores, dim=1)\n",
    "      masked_argmaxs = torch.stack(masked_argmaxs, dim=1)\n",
    "    \n",
    "      return log_pointer_scores, masked_argmaxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chfNkq9_1fZG"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DP9SfepP1g2F"
   },
   "source": [
    "Now we prepare for training. We first construct a class to calculate and track the averages for an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz8LcfC6gqBA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  \"\"\"\n",
    "  Computes and stores the average and current value\n",
    "\n",
    "  Adapted from pointer-networks-pytorch by ast0414:\n",
    "    https://github.com/ast0414/pointer-networks-pytorch\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.history = []\n",
    "    self.reset(record=False)\n",
    "\n",
    "  def reset(\n",
    "    self,\n",
    "    record: bool = True\n",
    "  ):\n",
    "    if record:\n",
    "      self.history.append(self.avg)\n",
    "    self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(\n",
    "    self,\n",
    "    val: Union[float, int],\n",
    "    n: int = 1\n",
    "  ):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "def masked_accuracy(\n",
    "  output: torch.Tensor,\n",
    "  target: torch.Tensor,\n",
    "  mask: torch.Tensor\n",
    ") -> float:\n",
    "  \"\"\"\n",
    "  Compute accuracy of softmax output with mask applied over values.\n",
    "\n",
    "  Adapted from pointer-networks-pytorch by ast0414:\n",
    "    https://github.com/ast0414/pointer-networks-pytorch\n",
    "  \"\"\"\n",
    "\n",
    "  with torch.no_grad():\n",
    "    masked_output = torch.masked_select(output, mask)\n",
    "    masked_target = torch.masked_select(target, mask)\n",
    "    accuracy = masked_output.eq(masked_target).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "def calculate_opt_dist(data, length):\n",
    "    distance = 0\n",
    "    for i in range(length-1):\n",
    "        distance += np.linalg.norm(data[i] -  data[i+1])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXeecaVt1z0y"
   },
   "source": [
    "We generate a set of training and validation datasets to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = TSPDataset50()\n",
    "val = TSPDatasetTest50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2ipU8hj15Di"
   },
   "source": [
    "With these put in place, we create and train a model. Feel free to modify the arguments below to see how they affect the performance and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "c_inputs = 2\n",
    "c_embed = 16\n",
    "c_hidden = 16\n",
    "n_heads = 4\n",
    "n_layers = 3\n",
    "dropout = 0.0\n",
    "use_cuda = True\n",
    "n_workers = 2\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "log_interval = 500\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size,\n",
    "  num_workers=n_workers, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size,\n",
    "  num_workers=n_workers)\n",
    "\n",
    "model = ConvexNet(c_inputs=c_inputs, c_embed=c_embed, n_heads=n_heads,\n",
    "  n_layers=n_layers, dropout=dropout, c_hidden=c_hidden).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.NLLLoss(ignore_index=TOKENS['<eos>'])\n",
    "\n",
    "train_loss = AverageMeter()\n",
    "train_accuracy = AverageMeter()\n",
    "val_loss = AverageMeter()\n",
    "val_accuracy = AverageMeter()\n",
    "\n",
    "# begin training\n",
    "for epoch in range(n_epochs):\n",
    "  model.train()\n",
    "  for bat, (batch_data, batch_labels, batch_lengths, data_) in enumerate(train_loader):\n",
    "    batch_data = batch_data.to(device)\n",
    "    batch_labels = batch_labels.to(device)\n",
    "    batch_lengths = batch_lengths.to(device)\n",
    "    data_ = data_.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #print(batch_data.shape, batch_labels.shape, batch_lengths)\n",
    "    log_pointer_scores, pointer_argmaxs = model(batch_data, batch_lengths, batch_labels=batch_labels)\n",
    "    #print(log_pointer_scores.shape, pointer_argmaxs.shape)\n",
    "    loss = criterion(log_pointer_scores.view(-1, log_pointer_scores.shape[-1]), batch_labels[:, 1:].reshape(-1))\n",
    "    assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss.update(loss.item(), batch_data.size(0))\n",
    "    mask = batch_labels[:, 1:] != TOKENS['<eos>']\n",
    "    acc = masked_accuracy(pointer_argmaxs, batch_labels[:, 1:], mask).item()\n",
    "    train_accuracy.update(acc, mask.int().sum().item())\n",
    "\n",
    "    if bat % log_interval == 0:\n",
    "      print(f'Epoch {epoch}: '\n",
    "            f'Train [{bat * len(batch_data):9d}/{len(train):9d} '\n",
    "            f'Loss: {train_loss.avg:.6f}\\tAccuracy: {train_accuracy.avg:3.4%}')\n",
    "    \n",
    "  model.eval()\n",
    "  opt_dists = []\n",
    "  for bat, (batch_data, batch_labels, batch_lengths, data_) in enumerate(val_loader):\n",
    "    batch_data = batch_data.to(device)\n",
    "    batch_labels = batch_labels.to(device)\n",
    "    batch_lengths = batch_lengths.to(device)\n",
    "    data_ = data_.to(device)\n",
    "    \n",
    "    log_pointer_scores, pointer_argmaxs = model(batch_data, batch_lengths, batch_labels=batch_labels, training = False)\n",
    "    \n",
    "    loss = criterion(log_pointer_scores.view(-1, log_pointer_scores.shape[-1]), batch_labels[:, 1:].reshape(-1))\n",
    "    assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "    val_loss.update(loss.item(), batch_data.size(0))\n",
    "    mask = batch_labels[:, 1:] != TOKENS['<eos>']\n",
    "    acc = masked_accuracy(pointer_argmaxs, batch_labels[:, 1:], mask).item()\n",
    "    val_accuracy.update(acc, mask.int().sum().item())\n",
    "\n",
    "    for data, length, ptr in zip(batch_data.cpu(), batch_lengths.cpu(),\n",
    "        pointer_argmaxs.cpu()):\n",
    "      opt_dists.append(calculate_opt_dist(data_.cpu().numpy()[0], len(ptr)))\n",
    "\n",
    "  print(f'Epoch {epoch}: Val\\Loss: {val_loss.avg:.6f} '\n",
    "        f'\\tAccuracy: {val_accuracy.avg:3.4%} '\n",
    "        f'\\tPredicted_Optimal_Distance: {np.mean(opt_dists)}')\n",
    "  train_loss.reset()\n",
    "  train_accuracy.reset()\n",
    "  val_loss.reset()\n",
    "  val_accuracy.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "SatnROvOS1_W",
    "outputId": "16cc30ef-bc40-4da5-ba1f-19fce20089e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display metrics and curves\n",
    "idx_best_train_loss = np.argmin(train_loss.history)\n",
    "best_train_loss = train_loss.history[idx_best_train_loss]\n",
    "idx_best_train_accuracy = np.argmax(train_accuracy.history)\n",
    "best_train_accuracy = train_accuracy.history[idx_best_train_accuracy]\n",
    "idx_best_val_loss = np.argmin(val_loss.history)\n",
    "best_val_loss = val_loss.history[idx_best_val_loss]\n",
    "idx_best_val_accuracy = np.argmax(val_accuracy.history)\n",
    "best_val_accuracy = val_accuracy.history[idx_best_val_accuracy]\n",
    "print('Best Scores:')\n",
    "print(f'train_loss: {best_train_loss:.4f} (ep: {idx_best_train_loss})')\n",
    "print(f'train_accuracy {best_train_accuracy:3.2%} (ep: {idx_best_train_accuracy})')\n",
    "print(f'val_loss: {best_val_loss:.4f} (ep: {idx_best_val_loss})')\n",
    "print(f'val_accuracy: {best_val_accuracy:3.2%} (ep: {idx_best_val_accuracy})')\n",
    "\n",
    "x_epochs = list(range(n_epochs))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].plot(x_epochs, train_loss.history, 'b')\n",
    "ax[0].plot(x_epochs, val_loss.history, 'r')\n",
    "_ = ax[0].set_title('Train vs. Val Loss')\n",
    "ax[1].plot(x_epochs, train_accuracy.history, 'b', label='Train')\n",
    "ax[1].plot(x_epochs, val_accuracy.history, 'r', label='Val')\n",
    "_ = ax[1].set_title('Train vs. Val Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-2.0.1]",
   "language": "python",
   "name": "conda-env-pytorch-2.0.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
