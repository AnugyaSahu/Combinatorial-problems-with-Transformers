{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVX4UKhCsqlw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from py2opt.routefinder import RouteFinder\n",
    "from scipy.spatial import distance_matrix\n",
    "def tsp_opt(points):\n",
    "    \"\"\"\n",
    "    Dynamic programing solution for TSP - O(2^n*n^2)\n",
    "    https://gist.github.com/mlalevic/6222750\n",
    "\n",
    "    :param points: List of (x, y) points\n",
    "    :return: Optimal solution\n",
    "    \"\"\"\n",
    "\n",
    "    def length(x_coord, y_coord):\n",
    "        return np.linalg.norm(np.asarray(x_coord) - np.asarray(y_coord))\n",
    "\n",
    "    # Calculate all lengths\n",
    "    all_distances = [[length(x, y) for y in points] for x in points]\n",
    "    # Initial value - just distance from 0 to every other point + keep the track of edges\n",
    "    A = {(frozenset([0, idx+1]), idx+1): (dist, [0, idx+1]) for idx, dist in enumerate(all_distances[0][1:])}\n",
    "    cnt = len(points)\n",
    "    for m in range(2, cnt):\n",
    "        B = {}\n",
    "        for S in [frozenset(C) | {0} for C in itertools.combinations(range(1, cnt), m)]:\n",
    "            for j in S - {0}:\n",
    "                # This will use 0th index of tuple for ordering, the same as if key=itemgetter(0) used\n",
    "                B[(S, j)] = min([(A[(S-{j}, k)][0] + all_distances[k][j], A[(S-{j}, k)][1] + [j])\n",
    "                                 for k in S if k != 0 and k != j])\n",
    "        A = B\n",
    "    res = min([(A[d][0] + all_distances[0][d[1]], A[d][1]) for d in iter(A)])\n",
    "    return np.asarray(res[1])\n",
    "\n",
    "def tsp_2_opt(points):\n",
    "    \"\"\"\n",
    "    2-Opt programing solution for TSP\n",
    "    https://github.com/pdrm83/py2opt\n",
    "\n",
    "    :param points: List of (x, y) points\n",
    "    :return: Best solution\n",
    "    \"\"\"\n",
    "    point_idx = list(range(len(points)))\n",
    "    dist_mat = distance_matrix(points, points)\n",
    "\n",
    "    route_finder = RouteFinder(dist_mat, point_idx, iterations=5)\n",
    "    best_distance, best_route = route_finder.solve()\n",
    "\n",
    "    return np.array(best_route), best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "xjJmtzGxs1RS",
    "outputId": "233153a7-8449-4268-bd1f-9397704690fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Reading the data from text files \n",
    "#Real world datasets or collected through a process not random, in form of coordinates\n",
    "#Some datasets are with different number of cities , the biggest dataset with consistent number of cities and optimally ordered instances is TSP50 and TSP100 datasets split up into training and test datasets.\n",
    "#The datasets have already an optimal solution because they are ordered in the dataset , when we use the dataset we have to shuffle the various instances\n",
    "#Heuristic methods can also be used to compare to the given optimal solutions\n",
    "#Dynamic programming method takes too much time but other heuristic methods and deep learning methods tackle the complexity of the dataset , very easy to use since the given dataset is (50, 2) or (100, 2) as an instance in form of coordinates and input becomes easy to manage, output is a sequence of optimally ordered cities in size (50, 1) and optimal cost as a floating number which uses Euclidean distance\n",
    "\n",
    "\n",
    "\n",
    "def read_coordinates_from_file(file_path):\n",
    "    coordinates = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    x = float(parts[0])\n",
    "                    y = float(parts[1])\n",
    "                except(ValueError):\n",
    "                    continue\n",
    "                coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "file_path_test_50 = r\"tsp_unif_test50_100_100000.txt\"\n",
    "file_path_train_50 = r\"tsp_unif50_10000_100000_1000.txt\"\n",
    "file_path_test_100 = r\"tsp_unif_test100_100_100000.txt\"\n",
    "file_path_train_100 = r\"tsp_unif100_10000_100000_1000.txt\"\n",
    "\n",
    "coordinates_test50 = read_coordinates_from_file(file_path_test_50)\n",
    "test50 = np.array(coordinates_test50)\n",
    "coordinates_train50 = read_coordinates_from_file(file_path_train_50)\n",
    "train50 = np.array(coordinates_train50)\n",
    "\n",
    "coordinates_test100 = read_coordinates_from_file(file_path_test_100)\n",
    "test100 = np.array(coordinates_test100)\n",
    "\n",
    "coordinates_train100 = read_coordinates_from_file(file_path_train_100)\n",
    "train100 = np.array(coordinates_train100)\n",
    "\n",
    "print(test50.shape, train50.shape, test100.shape, train100.shape)\n",
    "\n",
    "testinstances50 = []\n",
    "for i in range(0, 5000, 50):\n",
    "    testinstances50.append(test50[i:i+50, :])\n",
    "testinstances50 = np.array(testinstances50)\n",
    "optimal_distances_test50 = []\n",
    "for i in range(testinstances50.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(testinstances50.shape[1]-1):\n",
    "        distance += np.linalg.norm(testinstances50[i][j] -  testinstances50[i][j+1])\n",
    "    optimal_distances_test50.append(distance)\n",
    "optimal_distances_test50 = np.array(optimal_distances_test50)\n",
    "\n",
    "traininstances50 = []\n",
    "for i in range(0, 1500000, 50):\n",
    "    traininstances50.append(train50[i:i+50, :])\n",
    "traininstances50 = np.array(traininstances50)\n",
    "optimal_distances_train50 = []\n",
    "for i in range(traininstances50.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(traininstances50.shape[1]-1):\n",
    "        distance += np.linalg.norm(traininstances50[i][j] -  traininstances50[i][j+1])\n",
    "    optimal_distances_train50.append(distance)\n",
    "optimal_distances_train50 = np.array(optimal_distances_train50)\n",
    "\n",
    "testinstances100 = []\n",
    "for i in range(0, 10000, 100):\n",
    "    testinstances100.append(test100[i:i+100, :])\n",
    "testinstances100 = np.array(testinstances100)\n",
    "optimal_distances_test100 = []\n",
    "for i in range(testinstances100.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(testinstances100.shape[1]-1):\n",
    "        distance += np.linalg.norm(testinstances100[i][j] -  testinstances100[i][j+1])\n",
    "    optimal_distances_test100.append(distance)\n",
    "optimal_distances_test100 = np.array(optimal_distances_test100)\n",
    "\n",
    "traininstances100 = []\n",
    "for i in range(0, 1000000, 100):\n",
    "    traininstances100.append(train100[i:i+100, :])\n",
    "traininstances100 = np.array(traininstances100)\n",
    "optimal_distances_train100 = []\n",
    "for i in range(traininstances100.shape[0]):\n",
    "    distance = 0\n",
    "    for j in range(traininstances100.shape[1]-1):\n",
    "        distance += np.linalg.norm(traininstances100[i][j] -  traininstances100[i][j+1])\n",
    "    optimal_distances_train100.append(distance)\n",
    "optimal_distances_train100 = np.array(optimal_distances_train100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_test100 = np.mean(optimal_distances_test100)\n",
    "mean_test50 = np.mean(optimal_distances_test50)\n",
    "mean_train100 = np.mean(optimal_distances_train100)\n",
    "mean_train50 = np.mean(optimal_distances_train50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 opt method on traininstances100\n",
    "\n",
    "random.seed(1)\n",
    "start = time.time()\n",
    "y_pred = []\n",
    "for i in traininstances100:\n",
    "    np.random.shuffle(i)\n",
    "    route, yp = tsp_2_opt(i)\n",
    "    y_pred.append(yp)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "abs_error = abs(mean_test50 - np.mean(y_pred))\n",
    "relative_error = abs_error/mean_test50\n",
    "print(abs_error, relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZgngQWBJe6s",
    "outputId": "bff5ccb5-cc78-4f3d-c138-70db9da5ad24"
   },
   "outputs": [],
   "source": [
    "#City swap method on traininstances100\n",
    "\n",
    "import numpy as np\n",
    "import math as math\n",
    "import pandas as pd\n",
    "\n",
    "def objective_calculator(solution,dataset): #Calculates the objective function value (cost) of any solution (tour)\n",
    "    cost = 0\n",
    "    for i in range(len(solution)-2):\n",
    "        cost += euclid_calculator(solution[i], solution[i+1],dataset)  #To the euclid_calculator function, send the cities in the solution whose objective function value will be calculated, two at a time\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def euclid_calculator(city_1, city_2, dataset): #Calculates the euclidean distance between any two cities in the dataset\n",
    "\n",
    "    return math.sqrt((dataset.loc[city_1-1,\"x\"]-dataset.loc[city_2-1,\"x\"])**2 + (dataset.loc[city_1-1,\"y\"]-dataset.loc[city_2-1,\"y\"])**2) #Calculates the euclidean distance with formula using the city coordinates in the \"dataset\" dataframe\n",
    "\n",
    "\n",
    "\n",
    "def city_swap(city_1,city_2,current_solution,dataset):\n",
    "\n",
    "    tour_choice=current_solution.copy()                #In these lines, an array called tour_choice is created to try the swap on that array first.\n",
    "    keeper=tour_choice[city_1].copy()\n",
    "    tour_choice[city_1]=tour_choice[city_2].copy()\n",
    "    tour_choice[city_2]=keeper\n",
    "\n",
    "    if objective_calculator(tour_choice,dataset) < objective_calculator(current_solution,dataset): #The objective function values ​​of the new tour we tried and the previous tour are compared, checking if the new solution is better      #The objective function value of the tour, which is the better solution, is printed\n",
    "        current_solution=tour_choice\n",
    "    return current_solution\n",
    "\n",
    "\n",
    "def main(dataset): #Argument of the main function is the dataset of the coordinates of the cities in \"euclidean space\"\n",
    "    np.random.seed(28) #You can choose random seed\n",
    "    partly_initial_solution= np.random.permutation(range(1,len(dataset)+1))  #Randomly sorts the city numbers and creates the starting tour (starting solution)\n",
    "    initial_solution = np.append(partly_initial_solution, [partly_initial_solution[0]]) #Adds the city at the beginning of the tour to the end of the tour to make the salesman return to where he started\n",
    "\n",
    "    current_solution = initial_solution #Assigns the initial solution to the current solution\n",
    "    for k in range(10): #Trying to swap all cities with each other using nested for loops (You can change that \"10\" as you wish)\n",
    "        for i in range(1,len(dataset)-1):\n",
    "            for j in range(i+1,len(dataset)):\n",
    "                current_solution = city_swap(i,j,current_solution,dataset) #The cities to be swapped in the loop are sent to the city_swap function, with the current solution and dataset\n",
    "\n",
    "    return objective_calculator(current_solution,dataset)\n",
    "\n",
    "def city_swap1(instance):\n",
    "    np.random.shuffle(instance)\n",
    "    new_instance = pd.DataFrame(instance)\n",
    "    new_instance = new_instance.rename(columns = {0:\"x\", 1: \"y\"})\n",
    "    sol = main(new_instance)\n",
    "    return sol\n",
    "\n",
    "start = time.time()\n",
    "ypred = []\n",
    "c=0\n",
    "for i in traininstances100:\n",
    "    result = city_swap1(i)\n",
    "    ypred.append(result)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "abs_error = abs(mean_train100 - np.mean(ypred))\n",
    "relative_error = abs_error/mean_train100\n",
    "print(abs_error, relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZgngQWBJe6s",
    "outputId": "bff5ccb5-cc78-4f3d-c138-70db9da5ad24"
   },
   "outputs": [],
   "source": [
    "# Genetic algorithm on traininstances100\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time                    #Required library to calculate Computational Time\n",
    "import random\n",
    "\n",
    "def calculate_distance(cities , solution):\n",
    "    solution_for_distance_calculation = np.append(solution, [solution[0]], axis=0) #Appends the city index at the beginning of the solution array to the end of the array\n",
    "    distance = 0\n",
    "    next_city_index_founder=0\n",
    "\n",
    "    for i in solution_for_distance_calculation: #i will hold first city indexes\n",
    "        next_city_index_founder += 1\n",
    "        if next_city_index_founder < len(solution_for_distance_calculation):\n",
    "            next_city_index=solution_for_distance_calculation[next_city_index_founder] #Find the second city indexes here\n",
    "            distance += np.sqrt(((cities[next_city_index,0]-cities[i,0])**2)+((cities[next_city_index,1]-cities[i,1])**2)) #First city and second city indexes are used when calculating euclidean distance\n",
    "\n",
    "    return distance\n",
    "\n",
    "def parent_selection(population, number_of_pairs_M):\n",
    "    current_parents = []\n",
    "\n",
    "    #Parent selection from a population\n",
    "    parent_counter = 1\n",
    "\n",
    "    while parent_counter <= 2*number_of_pairs_M: #We will select twice as many parents as the desired number of parent \"pairs\" i.e. M, so a parent will be selected every time this loop is iterated\n",
    "\n",
    "        random_float = random.uniform(0,population[\"fitness\"].sum()) #A float number is randomly selected in the range of 0 and the sum of fitness values\n",
    "        cumulative_counter = 0 #Variable to assign the larger number in the cumulative test\n",
    "\n",
    "        for solution, fitness in population.itertuples(index=False):\n",
    "\n",
    "            cumulative_counter_copy = cumulative_counter   #cumulative_counter_copy is the variable to assign the smaller number in the cumulative test\n",
    "            cumulative_counter += fitness\n",
    "\n",
    "            if cumulative_counter_copy <= random_float <= cumulative_counter:   #If the randomly generated float number is in the cumulative range, the parent in question is selected\n",
    "\n",
    "                append_checker = True #But first, check if the solution in question is already in the current parent list\n",
    "                for parent in current_parents:\n",
    "                    if parent is solution:\n",
    "                        append_checker = False\n",
    "\n",
    "\n",
    "                if append_checker == True: #If the solution in question is not found in the current parent list, it is appended\n",
    "                    current_parents.append(solution)\n",
    "                    parent_counter += 1\n",
    "\n",
    "    return current_parents\n",
    "\n",
    "\n",
    "def crossover(current_parents, crossover_probability):\n",
    "    children = [] #Children created with crossover will be kept in this list\n",
    "    for parent_index_holder in range(1, len(current_parents)): #Loop created to iterate from the second parent\n",
    "        if random.uniform(0,1) < crossover_probability: #Crossover to parent pairs with the probability specified in the crossover_probability argument\n",
    "\n",
    "            parent_1 = current_parents[parent_index_holder-1]\n",
    "            parent_2 = current_parents[parent_index_holder]\n",
    "\n",
    "            left_bound = random.randint(1, len(current_parents[0])) #left border of crossover is randomly determined\n",
    "            right_bound = random.randint(left_bound, len(current_parents[0])) #right border of crossover is randomly determined\n",
    "\n",
    "            #Child creation as a result of crossover is done here\n",
    "            child =np.array([]) #An empty array is created to create its child\n",
    "            for j in range(left_bound): #The part of the child from the beginning to the left bound comes from parent 1\n",
    "                child = np.append(child, parent_1[j])\n",
    "\n",
    "            for k in range(left_bound,right_bound): #The part of child between left bound and right bound comes from parent 2\n",
    "                child = np.append(child, parent_2[k])\n",
    "\n",
    "            for l in range(right_bound, len(parent_1)): #The part of the child from the right bound to the end comes from parent 1\n",
    "                child = np.append(child, parent_1[l])\n",
    "\n",
    "            #Mappings for currently created children are created here\n",
    "            maps_list = []\n",
    "            for m in range(left_bound, right_bound):\n",
    "                maps_list.append([parent_1[m],parent_2[m]])\n",
    "\n",
    "            #Fix the infeasible child here\n",
    "            child = infeasible_child_fixer(child, maps_list)\n",
    "\n",
    "            #Created child are appended to the children array\n",
    "            children.append(child)\n",
    "\n",
    "    return children\n",
    "\n",
    "def infeasible_child_fixer(child, maps_list):\n",
    "    #print(\"Mappings: \",maps_list)              #You can print mappings for current child if you want\n",
    "    #print(\"Ve child ilk hali bu: \" , child)    #You can print current child before fixing\n",
    "\n",
    "    i=1\n",
    "    while i==1:\n",
    "\n",
    "        controlled_city_index_holder = -1\n",
    "        for controlled_city in child: #The number of each city in child will be checked\n",
    "            controlled_city_index_holder += 1\n",
    "\n",
    "            city_counter = 0 #This variable will keep the number of currently checked city in that child solution\n",
    "            for city in child: #The number of currently checked city is found in this for loop\n",
    "                if city == controlled_city:\n",
    "                    city_counter += 1\n",
    "\n",
    "            if city_counter < 2:\n",
    "\n",
    "                will_break = False\n",
    "\n",
    "            if city_counter > 1: #If controlled city is more than 1 in the current child solution; we need to replace controlled_city with the city it is mapped to\n",
    "                for a_map in maps_list:\n",
    "                    if a_map[0] == controlled_city: #Mapping where controlled_city is located\n",
    "\n",
    "                        child[controlled_city_index_holder] = a_map[1] #Replace the controlled city in the child solution with the other city in that mapping\n",
    "\n",
    "                        will_break = True\n",
    "\n",
    "                        maps_list.remove(a_map)          #Used mapping is removed from the mapping list\n",
    "\n",
    "                        break\n",
    "\n",
    "                    elif a_map[1] == controlled_city: #Mapping where controlled_city is located\n",
    "\n",
    "                        child[controlled_city_index_holder] = a_map[0] #Replace the controlled city in the child solution with the other city in that mapping\n",
    "\n",
    "                        will_break = True\n",
    "\n",
    "                        maps_list.remove(a_map)         #Used mapping is removed from the mapping list\n",
    "\n",
    "                        break\n",
    "\n",
    "\n",
    "            if will_break:\n",
    "                break\n",
    "        #print(\"This is the new version of the child solution after the change: \",child)        #You can print the new version of the child solution after the change\n",
    "\n",
    "        #There was a change in the child solution, so we have to start the checking process from the beginning\n",
    "\n",
    "        #But first we check if the child solution is fixed\n",
    "        child_fixed = True\n",
    "        city_counts = []\n",
    "        for city in child:\n",
    "            count = 0\n",
    "\n",
    "            for check in child:\n",
    "                if city == check:\n",
    "                    count += 1\n",
    "\n",
    "            city_counts.append([city, count])\n",
    "        #print(\"Here is the list of cities in the new version of the child solution and how many they are:\", city_counts)   #You can print the list of cities in the new version of the child solution and how many they are\n",
    "\n",
    "        #Check if any city is more than 1 in the new child solution\n",
    "        for count in city_counts:\n",
    "            if count[1] > 1:\n",
    "                child_fixed = False\n",
    "\n",
    "        #If the child solution is fixed, we finish checking it.\n",
    "        if child_fixed:\n",
    "            i=2\n",
    "            break\n",
    "\n",
    "    #print(\"Fixed version of that child solution: \", child) #You can print the fixed version of that child solution\n",
    "    return child\n",
    "\n",
    "\n",
    "#Apply mutation to child solutions, with a probability, by inverting a random part of it\n",
    "def mutate_children(children, mutation_probability):\n",
    "    children_after_mutation = []\n",
    "\n",
    "    for child in children:\n",
    "        if random.uniform(0, 1) <= mutation_probability:\n",
    "            left_bound = random.randint(0,len(child))\n",
    "            right_bound = random.randint(left_bound,len(child))\n",
    "            child[left_bound:right_bound] = child[left_bound:right_bound][::-1]\n",
    "            children_after_mutation.append(child)\n",
    "        else:\n",
    "            children_after_mutation.append(child)\n",
    "\n",
    "    return children_after_mutation\n",
    "\n",
    "def generation_creator(population, mutated_children, cities):\n",
    "    #A dataframe named \"children\" containing children and fitness values is created\n",
    "    integer_mutated_children = []\n",
    "    mutated_children_fitnesses = []\n",
    "    for child in mutated_children:\n",
    "        child = child.astype(int)\n",
    "        integer_mutated_children.append(child)\n",
    "        distance = calculate_distance(cities,child)\n",
    "        fitness = 1/distance\n",
    "        mutated_children_fitnesses.append(fitness)\n",
    "    children = pd.DataFrame(list(zip(integer_mutated_children,mutated_children_fitnesses)),columns=['solution','fitness'])\n",
    "    children.sort_values(by='fitness',axis=0,inplace=True,ascending=False)\n",
    "\n",
    "    #The best half of the children are selected to be included in the population\n",
    "    choosen_children_number = round(len(children)/2)\n",
    "    choosen_children = children.head(choosen_children_number)\n",
    "\n",
    "    #From the worst members of the current population, as many solutions as children to be added are discarded\n",
    "    population = population.head(len(population)-choosen_children_number)\n",
    "\n",
    "    #Selected children are added to the remaining solutions in the population; new population is also sorted by fitness\n",
    "    new_population = pd.concat([population, choosen_children])\n",
    "    new_population.sort_values(by='fitness',axis=0,inplace=True,ascending=False)\n",
    "\n",
    "    return new_population\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(generation_number, number_of_individuals, number_of_pairs_M, crossover_probability, mutation_probability):\n",
    "\n",
    "    #k = 0 #keeps the current generation number\n",
    "\n",
    "    #A dataframe named \"population\" containing initial population and fitness values is created\n",
    "    #solutions = []\n",
    "    #fitnesses = []\n",
    "    for j in traininstances100:\n",
    "        solutions = []\n",
    "        fitnesses = []\n",
    "        k = 0\n",
    "        for i in range(0,number_of_individuals): #for loop's range is number_of_individuals, since there will be as many individuals in the population as are entered as argument\n",
    "            solution=np.random.permutation(len(np.array(j)))\n",
    "            solutions.append(solution)\n",
    "            distance = calculate_distance(np.array(j), solution)\n",
    "            fitness = 1/distance                 #The fitness value of a solution (i.e. an individual) is calculated with 1/distance\n",
    "            fitnesses.append(fitness)\n",
    "        population = pd.DataFrame(list(zip(solutions,fitnesses)),columns=['solution','fitness'])\n",
    "        population.sort_values(by='fitness',axis=0,inplace=True,ascending=False)  #Individuals in the population are ranked in descending order of fitness values\n",
    "\n",
    "        print(\"Initial population: \")  #Initial population is printed\n",
    "        print(population)\n",
    "\n",
    "        #Genetic search starts (new generations will be produced as many as the desired generation number)\n",
    "        for i in range(generation_number):\n",
    "            k+=1\n",
    "\n",
    "        #parents are created to produce the next generation\n",
    "            current_parents = parent_selection(population, number_of_pairs_M)\n",
    "\n",
    "\n",
    "        #Child solutions are created by crossover\n",
    "            children = crossover(current_parents, crossover_probability)\n",
    "\n",
    "\n",
    "        #Child solutions are mutated with a probability\n",
    "            mutated_children = mutate_children(children, mutation_probability) #inversion mutation uyguladık\n",
    "\n",
    "\n",
    "        #Replacement is done and new generation is created\n",
    "            population = generation_creator(population, mutated_children, np.array(j))\n",
    "            print(\"--------------------------\")\n",
    "            print(\"Generation number: \",k )\n",
    "            \n",
    "            \n",
    "            if k == generation_number:\n",
    "                print(population)\n",
    "                for solution, fitness in population.itertuples(index=False):\n",
    "                    print(\"Best solution founded: \", np.append(solution, [solution[0]], axis=0))\n",
    "                    print(\"Cost of that solution: \", calculate_distance(np.array(j) , solution) )\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "start_time = time.time()                 #Keeps the start time\n",
    "\n",
    "main(1500, 100, 25, 0.7, 0.5) #(generation number, number of individuals in a generation, Number of parent \"pairs\" to be selected in parent selection, crossover probability for a parent pair, mutation probability for a child solution)\n",
    "\n",
    "comp_time = time.time() - start_time     #Subtracts the start time from the end time and keeps the result\n",
    "print(f\"-> Computational Time: {comp_time} seconds\")     #Prints computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtXU-_kLQEXA"
   },
   "outputs": [],
   "source": [
    "#Simulated annealing on traininstances100\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time                    #Required library to calculate Computational Time\n",
    "\n",
    "start_time = time.time()                 #Keeps the start time\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "def calculate_distance(cities , solution):\n",
    "    solution_for_distance_calculation = np.append(solution, [solution[0]], axis=0) #Appends the city index at the beginning of the solution array to the end of the array\n",
    "    distance = 0\n",
    "    next_city_index_founder=0\n",
    "\n",
    "    for i in solution_for_distance_calculation: #i will hold first city indexes\n",
    "        next_city_index_founder += 1\n",
    "        if next_city_index_founder < len(solution_for_distance_calculation):\n",
    "            next_city_index=solution_for_distance_calculation[next_city_index_founder] #Find the second city indexes here\n",
    "            distance += np.sqrt(((cities[next_city_index,0]-cities[i,0])**2)+((cities[next_city_index,1]-cities[i,1])**2)) #First city and second city indexes are used when calculating euclidean distance\n",
    "\n",
    "    return distance\n",
    "\n",
    "def generate_solution(current_solution): #A new solution will be created by swapping two random cities in the current solution\n",
    "    idx1 , idx2 = np.random.choice(len(current_solution),2)\n",
    "    current_solution_copy = current_solution.copy()\n",
    "    current_solution_copy[idx2], current_solution_copy[idx1] = current_solution_copy[idx1], current_solution_copy[idx2]\n",
    "    return current_solution_copy\n",
    "\n",
    "\n",
    "\n",
    "def main(dataset, T, cooling_rate, T_lower_bound, tolerance):\n",
    "    \n",
    "    for i in dataset:\n",
    "        data = pd.DataFrame(i)\n",
    "        cities = np.array(i)\n",
    "\n",
    "        current_solution = np.random.permutation(range(len(data))) #A random initial solution is created using city indexes\n",
    "        h=0 #Keeps the number of iterations\n",
    "        T_new = T\n",
    "        while T_new > T_lower_bound: #We want the algorithm to run when the temperature is greater than T_lower_bound\n",
    "            h+=1\n",
    "            while True: #Local search will be done here; different solutions will be tried for the \"same\" temperature value, until new solutions give very close values ​​to the current solution (that is, until the difference in costs between the new potential solution and the current solution is less than the tolerance)\n",
    "                potential_solution = generate_solution(current_solution) #The potential solution is created using the generate_solution function\n",
    "                potential_distance = calculate_distance(cities , potential_solution) #The cost of the potential solution is calculated with the calculate_distance function\n",
    "                current_distance = calculate_distance(cities , current_solution) #The cost of the current solution is calculated with the calculate_distance function\n",
    "\n",
    "\n",
    "                if potential_distance < current_distance: #If the potential solution is better, the potential solution is accepted\n",
    "                    current_solution = potential_solution\n",
    "\n",
    "\n",
    "                elif np.random.random() < np.exp(-(potential_distance - current_distance)/T): #Potential solution has a chance to be accepted based on a probability even if it is worse\n",
    "                    current_solution = potential_solution\n",
    "\n",
    "\n",
    "                if np.abs(potential_distance-current_distance) < tolerance: #Local search will run until a potential solution gives a cost value very close to the current solution\n",
    "                    break\n",
    "\n",
    "\n",
    "            T_new = T_new*cooling_rate #The temperature is updated depending on the cooling rate\n",
    "\n",
    "        print(\"--------RESULTS---------\")\n",
    "        print(\"Best tour founded for salesman: \", np.append(current_solution, [current_solution[0]], axis=0))\n",
    "        print(\"Distance of tour founded: \", current_distance)\n",
    "        print(\"Iterations: \",h )\n",
    "    comp_time = time.time() - start_time     #Keeps the difference between the end time and the start time\n",
    "    print(f\"-> Computational Time: {comp_time} seconds\")     #Prints Computational Time\n",
    "\n",
    "main(traininstances100, 100 , 0.999, 0.01, 1)   #(Dataset including city coordinates, Starting temperature, Cooling rate, Lower bound of temperature, Tolerance of local search) You can set these arguments as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_distances_train100[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
